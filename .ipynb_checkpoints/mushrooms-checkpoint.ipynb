{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hypertools as hyp \n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
       "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
       "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
       "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
       "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
       "\n",
       "         8         9     ...           81         82        83        84  \\\n",
       "0 -12.23257   7.83089    ...     13.01620  -54.40548  58.99367  15.37344   \n",
       "1  -0.92019  18.76548    ...      5.66812  -19.68073  33.04964  42.87836   \n",
       "2  -2.35035  16.07017    ...      3.03800   26.05866 -50.92779  10.93792   \n",
       "3 -10.34124   3.55005    ...     34.57337 -171.70734 -16.96705 -46.67617   \n",
       "4  -9.37636  12.63699    ...      9.92661  -55.95724  64.92712 -17.72522   \n",
       "\n",
       "         85        86         87        88         89        90  \n",
       "0   1.11144 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
       "1  -9.90378 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
       "2  -0.07568  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
       "3 -12.51516  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
       "4  -1.49237  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('YearPredictionMSD.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>timb_avg0</th>\n",
       "      <th>timb_avg1</th>\n",
       "      <th>timb_avg2</th>\n",
       "      <th>timb_avg3</th>\n",
       "      <th>timb_avg4</th>\n",
       "      <th>timb_avg5</th>\n",
       "      <th>timb_avg6</th>\n",
       "      <th>timb_avg7</th>\n",
       "      <th>timb_avg8</th>\n",
       "      <th>...</th>\n",
       "      <th>timb_cov68</th>\n",
       "      <th>timb_cov69</th>\n",
       "      <th>timb_cov70</th>\n",
       "      <th>timb_cov71</th>\n",
       "      <th>timb_cov72</th>\n",
       "      <th>timb_cov73</th>\n",
       "      <th>timb_cov74</th>\n",
       "      <th>timb_cov75</th>\n",
       "      <th>timb_cov76</th>\n",
       "      <th>timb_cov77</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  timb_avg0  timb_avg1  timb_avg2  timb_avg3  timb_avg4  timb_avg5  \\\n",
       "0  2001   49.94357   21.47114   73.07750    8.74861  -17.40628  -13.09905   \n",
       "1  2001   48.73215   18.42930   70.32679   12.94636  -10.32437  -24.83777   \n",
       "2  2001   50.95714   31.85602   55.81851   13.41693   -6.57898  -18.54940   \n",
       "3  2001   48.24750   -1.89837   36.29772    2.58776    0.97170  -26.21683   \n",
       "4  2001   50.97020   42.20998   67.09964    8.46791  -15.85279  -16.81409   \n",
       "\n",
       "   timb_avg6  timb_avg7  timb_avg8     ...      timb_cov68  timb_cov69  \\\n",
       "0  -25.01202  -12.23257    7.83089     ...        13.01620   -54.40548   \n",
       "1    8.76630   -0.92019   18.76548     ...         5.66812   -19.68073   \n",
       "2   -3.27872   -2.35035   16.07017     ...         3.03800    26.05866   \n",
       "3    5.05097  -10.34124    3.55005     ...        34.57337  -171.70734   \n",
       "4  -12.48207   -9.37636   12.63699     ...         9.92661   -55.95724   \n",
       "\n",
       "   timb_cov70  timb_cov71  timb_cov72  timb_cov73  timb_cov74  timb_cov75  \\\n",
       "0    58.99367    15.37344     1.11144   -23.08793    68.40795    -1.82223   \n",
       "1    33.04964    42.87836    -9.90378   -32.22788    70.49388    12.04941   \n",
       "2   -50.92779    10.93792    -0.07568    43.20130  -115.00698    -0.05859   \n",
       "3   -16.96705   -46.67617   -12.51516    82.58061   -72.08993     9.90558   \n",
       "4    64.92712   -17.72522    -1.49237    -7.50035    51.76631     7.88713   \n",
       "\n",
       "   timb_cov76  timb_cov77  \n",
       "0   -27.46348     2.26327  \n",
       "1    58.43453    26.92061  \n",
       "2    39.67068    -0.66345  \n",
       "3   199.62971    18.85382  \n",
       "4    55.66926    28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = [\"year\"] + [\"timb_avg\" + str(i) for i in range(12)] + [\"timb_cov\" + str(i) for i in range(78)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printResults(Y_test, pred, classifier=False):\n",
    "    print('Results:')\n",
    "\n",
    "    if classifier:\n",
    "        pred = [int(round(i)) for i in pred ]\n",
    "\n",
    "        print(\"Confusion Matrix:\\n\")\n",
    "        print(confusion_matrix(Y_test, pred))\n",
    "        print(classification_report(Y_test, pred))\n",
    "        \n",
    "        acc = accuracy_score(Y_test, pred)\n",
    "        print(\"Accuracy:\" + str(acc))\n",
    "        \n",
    "    print(\"MAE: \" + str(mean_absolute_error(Y_test, pred)))\n",
    "    print(\"MSE: \" + str(mean_squared_error(Y_test, pred)**0.5))\n",
    "    \n",
    "    \n",
    "    print('\\n' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training\n",
      "Done Predicting\n"
     ]
    }
   ],
   "source": [
    "### Regular dataset, regular linear regression\n",
    "#X = data.drop('year', axis=1)\n",
    "#Y = data['year']\n",
    "\n",
    "#pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "#X = pca.fit_transform(X)\n",
    "#print(X.shape)\n",
    "\n",
    "X_train = X[:463716, :]\n",
    "X_test = X[463716:, :] \n",
    "Y_train = Y[:463716]\n",
    "Y_test = Y[463716:]\n",
    "\n",
    "mod = LinearRegression()\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 7.68404352198\n",
      "MSE: 10.3629430123\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "### Regular dataset, 1-NN classifier\n",
    "X = data.drop('year', axis=1)\n",
    "Y = data['year']\n",
    "\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "X = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "X_train = X[:463716, :]\n",
    "X_test = X[463716:, :] \n",
    "Y_train = Y[:463716]\n",
    "Y_test = Y[463716:]\n",
    "\n",
    "mod = KNeighborsClassifier(n_neighbors=1)\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 10.3803989928\n",
      "MSE: 14.5725857577\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Predicting\n"
     ]
    }
   ],
   "source": [
    "### Regular dataset, Random Forest classifier\n",
    "X = data.drop('year', axis=1)\n",
    "Y = data['year']\n",
    "\n",
    "X_train = X.as_matrix()[:463716, :]\n",
    "X_test = X.as_matrix()[463716:, :] \n",
    "Y_train = Y[:463716]\n",
    "Y_test = Y[463716:]\n",
    "\n",
    "mod = RandomForestClassifier(verbose=2)\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 9.69896763447\n",
      "MSE: 14.5905196372\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 8.11305516679\n",
      "MSE: 10.8525026044\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Baseline\n",
    "\n",
    "mean = np.mean(Y_train)\n",
    "pred = [mean for i in pred]\n",
    "printResults(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Balances the dataset\n",
    "data = data[data['year'] > 1964]\n",
    "data = data[data['year'] < 2011]\n",
    "data.head()\n",
    "\n",
    "def bootstrap(data, num_to_extract=1000):\n",
    "    # This function will be applied on each group of instances of the same\n",
    "    # class in `data`.\n",
    "    def sampleClass(classgroup):\n",
    "        cls = classgroup['year'].iloc[0]\n",
    "        nDesired = num_to_extract\n",
    "        nRows = len(classgroup)\n",
    "\n",
    "        nSamples = min(nRows, nDesired)\n",
    "        return classgroup.sample(nSamples)\n",
    "\n",
    "    samples = data.groupby('year').apply(sampleClass)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "data = bootstrap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-efd1fc7c54cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprintResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "### Baseline\n",
    "\n",
    "mean = np.mean(Y_train)\n",
    "pred = [mean for i in pred]\n",
    "printResults(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training\n",
      "Done Predicting\n"
     ]
    }
   ],
   "source": [
    "### Balanced dataset, regular linear regression\n",
    "X = data.drop('year', axis=1)\n",
    "Y = data['year']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=101)\n",
    "\n",
    "mod = LinearRegression()\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 9.57441539896\n",
      "MSE: 11.4969799873\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Buckets by intuition\n",
    "data.ix[data.year < 1980, 'result'] = 0\n",
    "data.ix[(data.year > 1979) & (data.year < 2000), 'result'] = 1\n",
    "data.ix[(data.year > 1999) & (data.year < 2011), 'result'] = 2\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "data['result'] = labelEncoder.fit_transform(data['result'])\n",
    "\n",
    "X = data.drop('year', axis=1)\n",
    "X = X.drop('result', axis=1)\n",
    "Y = data['year']\n",
    "Z = data['result']\n",
    "\n",
    "#pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "#X = pca.fit_transform(X)\n",
    "#print(X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Z, test_size=0.1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Done Training\n",
      "Done Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## Buckets by intuition, logistic regression\n",
    "mod = LogisticRegression(verbose=2)\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 843  588  101]\n",
      " [ 419 1341  227]\n",
      " [ 194  465  422]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.55      0.56      1532\n",
      "          1       0.56      0.67      0.61      1987\n",
      "          2       0.56      0.39      0.46      1081\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4600\n",
      "\n",
      "Accuracy:0.56652173913\n",
      "MAE: 0.497608695652\n",
      "MSE: 0.791119185216\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Done Training\n",
      "Done Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "mod = RandomForestClassifier(verbose=2)\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 882  559   91]\n",
      " [ 566 1182  239]\n",
      " [ 231  472  378]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.58      0.55      1532\n",
      "          1       0.53      0.59      0.56      1987\n",
      "          2       0.53      0.35      0.42      1081\n",
      "\n",
      "avg / total       0.53      0.53      0.53      4600\n",
      "\n",
      "Accuracy:0.530869565217\n",
      "MAE: 0.539130434783\n",
      "MSE: 0.824093705098\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Y_test, pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = K(verbose=2)\n",
    "mod.fit(X_train, Y_train)\n",
    "print(\"Done Training\")\n",
    "\n",
    "pred = mod.predict(X_test)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Buckets by k-means\n",
    "data.ix[data.year < 1977, 'result'] = 0\n",
    "data.ix[(data.year > 1976) & (data.year < 1994), 'result'] = 1\n",
    "data.ix[(data.year > 1993) & (data.year < 2011), 'result'] = 2\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "data['result'] = labelEncoder.fit_transform(data['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Training\n",
      "Done Training\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "set_1 = data.ix[data.result == 0]\n",
    "X_1 = set_1.drop('year', axis=1)\n",
    "X_1 = X_1.drop('result', axis=1)\n",
    "Y_1 = set_1['year']\n",
    "Z_Y_1 = pd.concat([Y_1, set_1['result']], axis=1)\n",
    "\n",
    "X_train_1, X_test_1, Z_Y_train_1, Z_Y_test_1 = train_test_split(X_1, Z_Y_1, test_size=0.1, random_state=101)\n",
    "\n",
    "lin_reg_1 = LinearRegression()\n",
    "lin_reg_1.fit(X_train_1, Z_Y_train_1['year'])\n",
    "print(\"Done Training\")\n",
    "\n",
    "set_2 = data.ix[data.result == 1]\n",
    "X_2 = set_2.drop('year', axis=1)\n",
    "X_2 = X_2.drop('result', axis=1)\n",
    "Y_2 = set_2['year']\n",
    "Z_Y_2 = pd.concat([Y_2, set_2['result']], axis=1)\n",
    "\n",
    "X_train_2, X_test_2, Z_Y_train_2, Z_Y_test_2 = train_test_split(X_2, Z_Y_2, test_size=0.1, random_state=101)\n",
    "\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_train_2, Z_Y_train_2['year'])\n",
    "print(\"Done Training\")\n",
    "\n",
    "set_3 = data.ix[data.result == 2]\n",
    "X_3 = set_3.drop('year', axis=1)\n",
    "X_3 = X_3.drop('result', axis=1)\n",
    "Y_3 = set_3['year']\n",
    "Z_Y_3 = pd.concat([Y_3, set_3['result']], axis=1)\n",
    "\n",
    "X_train_3, X_test_3, Z_Y_train_3, Z_Y_test_3 = train_test_split(X_3, Z_Y_3, test_size=0.1, random_state=101)\n",
    "\n",
    "lin_reg_3 = LinearRegression()\n",
    "lin_reg_3.fit(X_train_3, Z_Y_train_3['year'])\n",
    "print(\"Done Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Done Training\n"
     ]
    }
   ],
   "source": [
    "X_train_total = pd.concat([X_train_1, X_train_2, X_train_3])\n",
    "X_test_total = pd.concat([X_test_1, X_test_2, X_test_3])\n",
    "Z_Y_train_total = pd.concat([Z_Y_train_1, Z_Y_train_2, Z_Y_train_3])\n",
    "Z_Y_test_total = pd.concat([Z_Y_test_1, Z_Y_test_2, Z_Y_test_3])\n",
    "\n",
    "## Buckets logistic regression\n",
    "log_buckets = LogisticRegression(verbose=2)\n",
    "log_buckets.fit(X_train_total, Z_Y_train_total['result'])\n",
    "print(\"Done Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Predicting\n"
     ]
    }
   ],
   "source": [
    "pred = log_buckets.predict(X_test_total)\n",
    "pred_proba = log_buckets.predict_proba(X_test_total)\n",
    "print(\"Done Predicting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Confusion Matrix:\n",
      "\n",
      "[[ 500  372  328]\n",
      " [ 259  972  469]\n",
      " [ 180  333 1187]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47      1200\n",
      "          1       0.58      0.57      0.58      1700\n",
      "          2       0.60      0.70      0.64      1700\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4600\n",
      "\n",
      "Accuracy:0.578043478261\n",
      "MAE: 0.532391304348\n",
      "MSE: 0.867906025768\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printResults(Z_Y_test_total['result'], pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "MAE: 9.55867547112\n",
      "MSE: 11.5333502975\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_bucket_pred = X_test_total\n",
    "\n",
    "X_bucket_pred['pred_1'] = pd.Series(pred_proba[:, 0], index=X_bucket_pred.index)\n",
    "X_bucket_pred['pred_2'] = pd.Series(pred_proba[:, 1], index=X_bucket_pred.index)\n",
    "X_bucket_pred['pred_3'] = pd.Series(pred_proba[:, 2], index=X_bucket_pred.index)\n",
    "\n",
    "X_Y_bucket_pred = pd.concat([X_bucket_pred, Z_Y_test_total['year']], axis=1)\n",
    "\n",
    "# X_Y_bucket_1 = X_Y_bucket_pred.ix[X_bucket_pred.pred == 0]\n",
    "# X_Y_bucket_2 = X_Y_bucket_pred.ix[X_bucket_pred.pred == 1]\n",
    "# X_Y_bucket_3 = X_Y_bucket_pred.ix[X_bucket_pred.pred == 2]\n",
    "\n",
    "# Final_pred_1 = pd.DataFrame({'pred': lin_reg_1.predict(X_Y_bucket_1.drop('year', axis=1).drop('pred', axis=1))})\n",
    "# Final_pred_2 = pd.DataFrame({'pred': lin_reg_2.predict(X_Y_bucket_2.drop('year', axis=1).drop('pred', axis=1))})\n",
    "# Final_pred_3 = pd.DataFrame({'pred': lin_reg_3.predict(X_Y_bucket_3.drop('year', axis=1).drop('pred', axis=1))})\n",
    "\n",
    "Feed_into_lin_reg = X_Y_bucket_pred.drop('year', axis=1).drop('pred_1', axis=1).drop('pred_2', axis=1).drop('pred_3', axis=1)\n",
    "X_Y_bucket_pred['pred_1_reg'] = pd.Series(lin_reg_1.predict(Feed_into_lin_reg), index=X_Y_bucket_pred.index)\n",
    "X_Y_bucket_pred['pred_2_reg'] = pd.Series(lin_reg_2.predict(Feed_into_lin_reg), index=X_Y_bucket_pred.index)\n",
    "X_Y_bucket_pred['pred_3_reg'] = pd.Series(lin_reg_3.predict(Feed_into_lin_reg), index=X_Y_bucket_pred.index)\n",
    "\n",
    "X_Y_bucket_pred['final_pred'] = X_Y_bucket_pred.pred_1 * X_Y_bucket_pred.pred_1_reg\n",
    "X_Y_bucket_pred['final_pred'] += X_Y_bucket_pred.pred_2 * X_Y_bucket_pred.pred_2_reg\n",
    "X_Y_bucket_pred['final_pred'] += X_Y_bucket_pred.pred_3 * X_Y_bucket_pred.pred_3_reg\n",
    "\n",
    "# Final_pred_total = pd.concat([Final_pred_1, Final_pred_2, Final_pred_3])\n",
    "# Final_Y_total = pd.concat([X_Y_bucket_1['year'], X_Y_bucket_2['year'], X_Y_bucket_3['year']])\n",
    "\n",
    "printResults(X_Y_bucket_pred['year'], X_Y_bucket_pred['final_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
